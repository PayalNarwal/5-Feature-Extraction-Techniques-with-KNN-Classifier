{"cells":[{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 240 validated image filenames belonging to 40 classes.\n","Found 80 validated image filenames belonging to 40 classes.\n","Found 80 validated image filenames belonging to 40 classes.\n","Epoch 1/1000\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\rahla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["4/4 - 5s - 1s/step - accuracy: 0.0250 - loss: 3.7124 - val_accuracy: 0.0250 - val_loss: 3.6896 - learning_rate: 3.0000e-04\n","Epoch 2/1000\n","4/4 - 2s - 458ms/step - accuracy: 0.0167 - loss: 3.6899 - val_accuracy: 0.0250 - val_loss: 3.6841 - learning_rate: 3.0000e-04\n","Epoch 3/1000\n","4/4 - 2s - 405ms/step - accuracy: 0.0417 - loss: 3.6861 - val_accuracy: 0.0500 - val_loss: 3.6845 - learning_rate: 3.0000e-04\n","Epoch 4/1000\n","4/4 - 2s - 427ms/step - accuracy: 0.0417 - loss: 3.6838 - val_accuracy: 0.0500 - val_loss: 3.6808 - learning_rate: 3.0000e-04\n","Epoch 5/1000\n","4/4 - 2s - 409ms/step - accuracy: 0.0458 - loss: 3.6815 - val_accuracy: 0.0500 - val_loss: 3.6794 - learning_rate: 3.0000e-04\n","Epoch 6/1000\n","4/4 - 2s - 438ms/step - accuracy: 0.0458 - loss: 3.6784 - val_accuracy: 0.0500 - val_loss: 3.6766 - learning_rate: 3.0000e-04\n","Epoch 7/1000\n","4/4 - 2s - 427ms/step - accuracy: 0.0500 - loss: 3.6743 - val_accuracy: 0.0625 - val_loss: 3.6670 - learning_rate: 3.0000e-04\n","Epoch 8/1000\n","4/4 - 2s - 408ms/step - accuracy: 0.0583 - loss: 3.6663 - val_accuracy: 0.0625 - val_loss: 3.6626 - learning_rate: 3.0000e-04\n","Epoch 9/1000\n","4/4 - 2s - 405ms/step - accuracy: 0.0500 - loss: 3.6581 - val_accuracy: 0.0750 - val_loss: 3.6450 - learning_rate: 3.0000e-04\n","Epoch 10/1000\n","4/4 - 2s - 406ms/step - accuracy: 0.0750 - loss: 3.6419 - val_accuracy: 0.0875 - val_loss: 3.6326 - learning_rate: 3.0000e-04\n","Epoch 11/1000\n","4/4 - 2s - 406ms/step - accuracy: 0.0625 - loss: 3.6285 - val_accuracy: 0.0375 - val_loss: 3.6211 - learning_rate: 3.0000e-04\n","Epoch 12/1000\n","4/4 - 2s - 408ms/step - accuracy: 0.0792 - loss: 3.6017 - val_accuracy: 0.0750 - val_loss: 3.5744 - learning_rate: 3.0000e-04\n","Epoch 13/1000\n","4/4 - 2s - 418ms/step - accuracy: 0.0667 - loss: 3.5523 - val_accuracy: 0.0875 - val_loss: 3.5162 - learning_rate: 3.0000e-04\n","Epoch 14/1000\n","4/4 - 2s - 410ms/step - accuracy: 0.0833 - loss: 3.5020 - val_accuracy: 0.0875 - val_loss: 3.4429 - learning_rate: 3.0000e-04\n","Epoch 15/1000\n","4/4 - 2s - 423ms/step - accuracy: 0.1042 - loss: 3.4436 - val_accuracy: 0.1125 - val_loss: 3.3421 - learning_rate: 3.0000e-04\n","Epoch 16/1000\n","4/4 - 2s - 409ms/step - accuracy: 0.1125 - loss: 3.3707 - val_accuracy: 0.0750 - val_loss: 3.3352 - learning_rate: 3.0000e-04\n","Epoch 17/1000\n","4/4 - 2s - 404ms/step - accuracy: 0.1083 - loss: 3.2682 - val_accuracy: 0.1125 - val_loss: 3.2158 - learning_rate: 3.0000e-04\n","Epoch 18/1000\n","4/4 - 2s - 422ms/step - accuracy: 0.1292 - loss: 3.2004 - val_accuracy: 0.1625 - val_loss: 3.1583 - learning_rate: 3.0000e-04\n","Epoch 19/1000\n","4/4 - 2s - 409ms/step - accuracy: 0.1375 - loss: 3.1348 - val_accuracy: 0.2000 - val_loss: 3.0878 - learning_rate: 3.0000e-04\n","Epoch 20/1000\n","4/4 - 2s - 409ms/step - accuracy: 0.1333 - loss: 3.0572 - val_accuracy: 0.1500 - val_loss: 3.0523 - learning_rate: 3.0000e-04\n","Epoch 21/1000\n","4/4 - 2s - 401ms/step - accuracy: 0.2042 - loss: 2.9098 - val_accuracy: 0.2750 - val_loss: 2.7715 - learning_rate: 3.0000e-04\n","Epoch 22/1000\n","4/4 - 2s - 410ms/step - accuracy: 0.2500 - loss: 2.8553 - val_accuracy: 0.2250 - val_loss: 2.7559 - learning_rate: 3.0000e-04\n","Epoch 23/1000\n","4/4 - 2s - 421ms/step - accuracy: 0.2333 - loss: 2.7340 - val_accuracy: 0.2500 - val_loss: 2.7011 - learning_rate: 3.0000e-04\n","Epoch 24/1000\n","4/4 - 2s - 414ms/step - accuracy: 0.2542 - loss: 2.6397 - val_accuracy: 0.3000 - val_loss: 2.5699 - learning_rate: 3.0000e-04\n","Epoch 25/1000\n","4/4 - 2s - 414ms/step - accuracy: 0.3292 - loss: 2.5369 - val_accuracy: 0.3625 - val_loss: 2.4109 - learning_rate: 3.0000e-04\n","Epoch 26/1000\n","4/4 - 2s - 410ms/step - accuracy: 0.3125 - loss: 2.3634 - val_accuracy: 0.3750 - val_loss: 2.2508 - learning_rate: 3.0000e-04\n","Epoch 27/1000\n","4/4 - 2s - 400ms/step - accuracy: 0.3750 - loss: 2.2362 - val_accuracy: 0.3500 - val_loss: 2.2385 - learning_rate: 3.0000e-04\n","Epoch 28/1000\n","4/4 - 2s - 402ms/step - accuracy: 0.4083 - loss: 2.1373 - val_accuracy: 0.4000 - val_loss: 2.0492 - learning_rate: 3.0000e-04\n","Epoch 29/1000\n","4/4 - 2s - 417ms/step - accuracy: 0.4167 - loss: 2.1351 - val_accuracy: 0.3875 - val_loss: 2.1541 - learning_rate: 3.0000e-04\n","Epoch 30/1000\n","4/4 - 2s - 404ms/step - accuracy: 0.4750 - loss: 1.9167 - val_accuracy: 0.3875 - val_loss: 2.0126 - learning_rate: 3.0000e-04\n","Epoch 31/1000\n","4/4 - 2s - 411ms/step - accuracy: 0.4250 - loss: 1.9524 - val_accuracy: 0.4125 - val_loss: 1.9816 - learning_rate: 3.0000e-04\n","Epoch 32/1000\n","4/4 - 2s - 415ms/step - accuracy: 0.4458 - loss: 1.9518 - val_accuracy: 0.4375 - val_loss: 1.9218 - learning_rate: 3.0000e-04\n","Epoch 33/1000\n","4/4 - 2s - 406ms/step - accuracy: 0.4333 - loss: 1.7961 - val_accuracy: 0.4750 - val_loss: 1.8099 - learning_rate: 3.0000e-04\n","Epoch 34/1000\n","4/4 - 2s - 434ms/step - accuracy: 0.5000 - loss: 1.7818 - val_accuracy: 0.5250 - val_loss: 1.7667 - learning_rate: 3.0000e-04\n","Epoch 35/1000\n","4/4 - 2s - 432ms/step - accuracy: 0.4875 - loss: 1.6268 - val_accuracy: 0.5000 - val_loss: 1.7615 - learning_rate: 3.0000e-04\n","Epoch 36/1000\n","4/4 - 2s - 418ms/step - accuracy: 0.4917 - loss: 1.6197 - val_accuracy: 0.5500 - val_loss: 1.6117 - learning_rate: 3.0000e-04\n","Epoch 37/1000\n","4/4 - 2s - 411ms/step - accuracy: 0.5000 - loss: 1.6795 - val_accuracy: 0.5625 - val_loss: 1.4920 - learning_rate: 3.0000e-04\n","Epoch 38/1000\n","4/4 - 2s - 400ms/step - accuracy: 0.5708 - loss: 1.4098 - val_accuracy: 0.5750 - val_loss: 1.5521 - learning_rate: 3.0000e-04\n","Epoch 39/1000\n","4/4 - 2s - 416ms/step - accuracy: 0.6042 - loss: 1.3924 - val_accuracy: 0.5750 - val_loss: 1.3619 - learning_rate: 3.0000e-04\n","Epoch 40/1000\n","4/4 - 2s - 417ms/step - accuracy: 0.5792 - loss: 1.5381 - val_accuracy: 0.5750 - val_loss: 1.4784 - learning_rate: 3.0000e-04\n","Epoch 41/1000\n","4/4 - 2s - 405ms/step - accuracy: 0.6208 - loss: 1.3080 - val_accuracy: 0.6000 - val_loss: 1.4994 - learning_rate: 3.0000e-04\n","Epoch 42/1000\n","4/4 - 2s - 403ms/step - accuracy: 0.6625 - loss: 1.2292 - val_accuracy: 0.5750 - val_loss: 1.4487 - learning_rate: 3.0000e-04\n","Epoch 43/1000\n","4/4 - 2s - 403ms/step - accuracy: 0.6333 - loss: 1.2595 - val_accuracy: 0.6750 - val_loss: 1.3519 - learning_rate: 3.0000e-04\n","Epoch 44/1000\n","4/4 - 2s - 411ms/step - accuracy: 0.6250 - loss: 1.2596 - val_accuracy: 0.6500 - val_loss: 1.1392 - learning_rate: 3.0000e-04\n","Epoch 45/1000\n","4/4 - 2s - 408ms/step - accuracy: 0.5667 - loss: 1.3475 - val_accuracy: 0.6375 - val_loss: 1.2712 - learning_rate: 3.0000e-04\n","Epoch 46/1000\n","4/4 - 2s - 408ms/step - accuracy: 0.6042 - loss: 1.2542 - val_accuracy: 0.6000 - val_loss: 1.4066 - learning_rate: 3.0000e-04\n","Epoch 47/1000\n","4/4 - 2s - 407ms/step - accuracy: 0.6583 - loss: 1.1377 - val_accuracy: 0.6000 - val_loss: 1.2603 - learning_rate: 3.0000e-04\n","Epoch 48/1000\n","4/4 - 2s - 403ms/step - accuracy: 0.6792 - loss: 1.2057 - val_accuracy: 0.6500 - val_loss: 1.3096 - learning_rate: 3.0000e-04\n","Epoch 49/1000\n","4/4 - 2s - 412ms/step - accuracy: 0.6667 - loss: 1.1109 - val_accuracy: 0.7375 - val_loss: 1.0640 - learning_rate: 3.0000e-04\n","Epoch 50/1000\n","4/4 - 2s - 402ms/step - accuracy: 0.6625 - loss: 1.1163 - val_accuracy: 0.6125 - val_loss: 1.2458 - learning_rate: 3.0000e-04\n","Epoch 51/1000\n","4/4 - 2s - 408ms/step - accuracy: 0.6542 - loss: 1.1172 - val_accuracy: 0.7375 - val_loss: 1.0803 - learning_rate: 3.0000e-04\n","Epoch 52/1000\n","4/4 - 2s - 411ms/step - accuracy: 0.7208 - loss: 0.9390 - val_accuracy: 0.6375 - val_loss: 1.1238 - learning_rate: 3.0000e-04\n","Epoch 53/1000\n","4/4 - 2s - 414ms/step - accuracy: 0.6875 - loss: 1.0399 - val_accuracy: 0.7000 - val_loss: 1.2359 - learning_rate: 3.0000e-04\n","Epoch 54/1000\n","4/4 - 2s - 419ms/step - accuracy: 0.7042 - loss: 1.0481 - val_accuracy: 0.6875 - val_loss: 1.0707 - learning_rate: 3.0000e-04\n","Epoch 55/1000\n","4/4 - 2s - 413ms/step - accuracy: 0.6292 - loss: 1.1416 - val_accuracy: 0.5875 - val_loss: 1.3331 - learning_rate: 3.0000e-04\n","Epoch 56/1000\n","4/4 - 2s - 406ms/step - accuracy: 0.7167 - loss: 0.9550 - val_accuracy: 0.6625 - val_loss: 1.0774 - learning_rate: 3.0000e-04\n","Epoch 57/1000\n","4/4 - 2s - 407ms/step - accuracy: 0.6833 - loss: 1.0864 - val_accuracy: 0.7375 - val_loss: 1.0966 - learning_rate: 3.0000e-04\n","Epoch 58/1000\n","4/4 - 2s - 408ms/step - accuracy: 0.7250 - loss: 0.9809 - val_accuracy: 0.6875 - val_loss: 1.1147 - learning_rate: 3.0000e-04\n","Epoch 59/1000\n","4/4 - 2s - 456ms/step - accuracy: 0.6833 - loss: 1.0498 - val_accuracy: 0.6875 - val_loss: 0.9681 - learning_rate: 3.0000e-04\n","Epoch 60/1000\n","4/4 - 2s - 404ms/step - accuracy: 0.6917 - loss: 0.9604 - val_accuracy: 0.7000 - val_loss: 1.0334 - learning_rate: 3.0000e-04\n","Epoch 61/1000\n","4/4 - 2s - 403ms/step - accuracy: 0.6625 - loss: 1.0306 - val_accuracy: 0.6875 - val_loss: 1.0677 - learning_rate: 3.0000e-04\n","Epoch 62/1000\n","4/4 - 2s - 401ms/step - accuracy: 0.7375 - loss: 0.8350 - val_accuracy: 0.7375 - val_loss: 0.8835 - learning_rate: 3.0000e-04\n","Epoch 63/1000\n","4/4 - 2s - 425ms/step - accuracy: 0.7458 - loss: 0.8756 - val_accuracy: 0.7000 - val_loss: 0.9278 - learning_rate: 3.0000e-04\n","Epoch 64/1000\n","4/4 - 2s - 446ms/step - accuracy: 0.6833 - loss: 0.9847 - val_accuracy: 0.6875 - val_loss: 1.1690 - learning_rate: 3.0000e-04\n","Epoch 65/1000\n","4/4 - 2s - 428ms/step - accuracy: 0.7333 - loss: 0.9264 - val_accuracy: 0.7375 - val_loss: 0.9058 - learning_rate: 3.0000e-04\n","Epoch 66/1000\n","4/4 - 2s - 428ms/step - accuracy: 0.7583 - loss: 0.9083 - val_accuracy: 0.7000 - val_loss: 0.9969 - learning_rate: 3.0000e-04\n","Epoch 67/1000\n","4/4 - 2s - 410ms/step - accuracy: 0.7542 - loss: 0.7954 - val_accuracy: 0.6875 - val_loss: 0.9322 - learning_rate: 3.0000e-04\n","Epoch 68/1000\n","4/4 - 2s - 413ms/step - accuracy: 0.7667 - loss: 0.8189 - val_accuracy: 0.6750 - val_loss: 1.0482 - learning_rate: 3.0000e-04\n","Epoch 69/1000\n","4/4 - 2s - 417ms/step - accuracy: 0.7750 - loss: 0.7616 - val_accuracy: 0.5750 - val_loss: 1.2102 - learning_rate: 3.0000e-04\n","Epoch 70/1000\n","4/4 - 2s - 412ms/step - accuracy: 0.7583 - loss: 0.7562 - val_accuracy: 0.7500 - val_loss: 0.8573 - learning_rate: 3.0000e-04\n","Epoch 71/1000\n","4/4 - 2s - 416ms/step - accuracy: 0.7333 - loss: 0.8261 - val_accuracy: 0.7125 - val_loss: 0.8948 - learning_rate: 3.0000e-04\n","Epoch 72/1000\n","4/4 - 2s - 406ms/step - accuracy: 0.6708 - loss: 0.9374 - val_accuracy: 0.8250 - val_loss: 0.6778 - learning_rate: 3.0000e-04\n","Epoch 73/1000\n","4/4 - 2s - 404ms/step - accuracy: 0.7708 - loss: 0.7799 - val_accuracy: 0.6750 - val_loss: 0.9782 - learning_rate: 3.0000e-04\n","Epoch 74/1000\n","4/4 - 2s - 413ms/step - accuracy: 0.7708 - loss: 0.8191 - val_accuracy: 0.5875 - val_loss: 1.1192 - learning_rate: 3.0000e-04\n","Epoch 75/1000\n","4/4 - 2s - 404ms/step - accuracy: 0.7792 - loss: 0.6488 - val_accuracy: 0.6625 - val_loss: 0.9789 - learning_rate: 3.0000e-04\n","Epoch 76/1000\n","4/4 - 2s - 405ms/step - accuracy: 0.7542 - loss: 0.8193 - val_accuracy: 0.6750 - val_loss: 0.9747 - learning_rate: 3.0000e-04\n","Epoch 77/1000\n","4/4 - 2s - 403ms/step - accuracy: 0.7708 - loss: 0.7324 - val_accuracy: 0.8375 - val_loss: 0.6601 - learning_rate: 3.0000e-04\n","Epoch 78/1000\n","4/4 - 2s - 399ms/step - accuracy: 0.8208 - loss: 0.6112 - val_accuracy: 0.7750 - val_loss: 0.7814 - learning_rate: 3.0000e-04\n","Epoch 79/1000\n","4/4 - 2s - 408ms/step - accuracy: 0.7833 - loss: 0.7203 - val_accuracy: 0.7375 - val_loss: 0.8152 - learning_rate: 3.0000e-04\n","Epoch 80/1000\n","4/4 - 2s - 402ms/step - accuracy: 0.8167 - loss: 0.5667 - val_accuracy: 0.7250 - val_loss: 0.8600 - learning_rate: 3.0000e-04\n","Epoch 81/1000\n","4/4 - 2s - 401ms/step - accuracy: 0.7708 - loss: 0.7468 - val_accuracy: 0.7250 - val_loss: 0.8729 - learning_rate: 3.0000e-04\n","Epoch 82/1000\n","4/4 - 2s - 402ms/step - accuracy: 0.7625 - loss: 0.7945 - val_accuracy: 0.7625 - val_loss: 0.7084 - learning_rate: 3.0000e-04\n","Epoch 83/1000\n","4/4 - 2s - 409ms/step - accuracy: 0.7833 - loss: 0.6208 - val_accuracy: 0.7500 - val_loss: 0.8850 - learning_rate: 3.0000e-04\n","Epoch 84/1000\n","4/4 - 2s - 423ms/step - accuracy: 0.7708 - loss: 0.6634 - val_accuracy: 0.7375 - val_loss: 1.0187 - learning_rate: 3.0000e-04\n","Epoch 85/1000\n","4/4 - 2s - 426ms/step - accuracy: 0.8125 - loss: 0.6925 - val_accuracy: 0.7750 - val_loss: 0.8803 - learning_rate: 3.0000e-04\n","Epoch 86/1000\n","4/4 - 2s - 428ms/step - accuracy: 0.8125 - loss: 0.6079 - val_accuracy: 0.8375 - val_loss: 0.5417 - learning_rate: 3.0000e-04\n","Epoch 87/1000\n","4/4 - 2s - 420ms/step - accuracy: 0.8250 - loss: 0.5475 - val_accuracy: 0.7500 - val_loss: 0.8570 - learning_rate: 3.0000e-04\n","Epoch 88/1000\n","4/4 - 2s - 420ms/step - accuracy: 0.7625 - loss: 0.6291 - val_accuracy: 0.7875 - val_loss: 0.8052 - learning_rate: 3.0000e-04\n","Epoch 89/1000\n","4/4 - 2s - 421ms/step - accuracy: 0.8625 - loss: 0.5222 - val_accuracy: 0.7500 - val_loss: 0.8707 - learning_rate: 3.0000e-04\n","Epoch 90/1000\n","4/4 - 2s - 404ms/step - accuracy: 0.7958 - loss: 0.6833 - val_accuracy: 0.8250 - val_loss: 0.5348 - learning_rate: 3.0000e-04\n","Epoch 91/1000\n","4/4 - 2s - 415ms/step - accuracy: 0.8417 - loss: 0.5755 - val_accuracy: 0.7500 - val_loss: 0.7255 - learning_rate: 3.0000e-04\n","Epoch 92/1000\n","4/4 - 2s - 404ms/step - accuracy: 0.8000 - loss: 0.6513 - val_accuracy: 0.7250 - val_loss: 0.8413 - learning_rate: 3.0000e-04\n","Epoch 93/1000\n","4/4 - 2s - 405ms/step - accuracy: 0.8333 - loss: 0.5390 - val_accuracy: 0.7500 - val_loss: 0.8616 - learning_rate: 3.0000e-04\n","Epoch 94/1000\n","4/4 - 2s - 417ms/step - accuracy: 0.8042 - loss: 0.5812 - val_accuracy: 0.7000 - val_loss: 0.8892 - learning_rate: 3.0000e-04\n","Epoch 95/1000\n","4/4 - 2s - 408ms/step - accuracy: 0.8208 - loss: 0.5525 - val_accuracy: 0.7375 - val_loss: 0.8434 - learning_rate: 3.0000e-04\n","Epoch 96/1000\n","4/4 - 2s - 432ms/step - accuracy: 0.8250 - loss: 0.5957 - val_accuracy: 0.7875 - val_loss: 0.7009 - learning_rate: 3.0000e-04\n","Epoch 97/1000\n","4/4 - 2s - 417ms/step - accuracy: 0.7833 - loss: 0.6766 - val_accuracy: 0.8125 - val_loss: 0.7828 - learning_rate: 3.0000e-04\n","Epoch 98/1000\n","4/4 - 2s - 410ms/step - accuracy: 0.8542 - loss: 0.5146 - val_accuracy: 0.7500 - val_loss: 0.8179 - learning_rate: 3.0000e-04\n","Epoch 99/1000\n","4/4 - 2s - 421ms/step - accuracy: 0.8208 - loss: 0.5788 - val_accuracy: 0.7375 - val_loss: 0.8150 - learning_rate: 3.0000e-04\n","Epoch 100/1000\n","4/4 - 2s - 410ms/step - accuracy: 0.8000 - loss: 0.5887 - val_accuracy: 0.7125 - val_loss: 0.8440 - learning_rate: 3.0000e-04\n","Epoch 101/1000\n","4/4 - 2s - 410ms/step - accuracy: 0.8083 - loss: 0.5767 - val_accuracy: 0.7625 - val_loss: 0.6464 - learning_rate: 3.0000e-04\n","Epoch 102/1000\n","4/4 - 2s - 407ms/step - accuracy: 0.7833 - loss: 0.6016 - val_accuracy: 0.7375 - val_loss: 0.8876 - learning_rate: 3.0000e-04\n","Epoch 103/1000\n","4/4 - 2s - 413ms/step - accuracy: 0.8375 - loss: 0.5499 - val_accuracy: 0.8250 - val_loss: 0.5932 - learning_rate: 3.0000e-04\n","Epoch 104/1000\n","4/4 - 2s - 411ms/step - accuracy: 0.8417 - loss: 0.5297 - val_accuracy: 0.7875 - val_loss: 0.6954 - learning_rate: 3.0000e-04\n","Epoch 105/1000\n","4/4 - 2s - 403ms/step - accuracy: 0.8500 - loss: 0.4961 - val_accuracy: 0.7500 - val_loss: 0.7087 - learning_rate: 3.0000e-04\n","Epoch 106/1000\n","4/4 - 2s - 420ms/step - accuracy: 0.8375 - loss: 0.5455 - val_accuracy: 0.7750 - val_loss: 0.6312 - learning_rate: 3.0000e-04\n","Epoch 107/1000\n","4/4 - 2s - 414ms/step - accuracy: 0.8000 - loss: 0.6149 - val_accuracy: 0.8000 - val_loss: 0.5480 - learning_rate: 3.0000e-04\n","Epoch 108/1000\n","4/4 - 2s - 426ms/step - accuracy: 0.7750 - loss: 0.7197 - val_accuracy: 0.8250 - val_loss: 0.6669 - learning_rate: 3.0000e-04\n","Epoch 109/1000\n","4/4 - 2s - 507ms/step - accuracy: 0.8500 - loss: 0.5267 - val_accuracy: 0.7500 - val_loss: 0.8443 - learning_rate: 3.0000e-04\n","Epoch 110/1000\n","\n","Epoch 110: ReduceLROnPlateau reducing learning rate to 6.000000284984708e-05.\n","4/4 - 2s - 525ms/step - accuracy: 0.8542 - loss: 0.4972 - val_accuracy: 0.6750 - val_loss: 0.8664 - learning_rate: 3.0000e-04\n","Epoch 111/1000\n","4/4 - 2s - 600ms/step - accuracy: 0.8375 - loss: 0.5467 - val_accuracy: 0.7750 - val_loss: 0.7388 - learning_rate: 6.0000e-05\n","Epoch 112/1000\n","4/4 - 2s - 544ms/step - accuracy: 0.8583 - loss: 0.4780 - val_accuracy: 0.8625 - val_loss: 0.5442 - learning_rate: 6.0000e-05\n","Epoch 113/1000\n","4/4 - 2s - 563ms/step - accuracy: 0.8958 - loss: 0.4102 - val_accuracy: 0.8500 - val_loss: 0.5465 - learning_rate: 6.0000e-05\n","Epoch 114/1000\n","4/4 - 2s - 547ms/step - accuracy: 0.8625 - loss: 0.4994 - val_accuracy: 0.8250 - val_loss: 0.5908 - learning_rate: 6.0000e-05\n","Epoch 115/1000\n","4/4 - 2s - 495ms/step - accuracy: 0.8667 - loss: 0.4408 - val_accuracy: 0.7750 - val_loss: 0.7170 - learning_rate: 6.0000e-05\n","Epoch 116/1000\n","4/4 - 2s - 417ms/step - accuracy: 0.8958 - loss: 0.4155 - val_accuracy: 0.8250 - val_loss: 0.4832 - learning_rate: 6.0000e-05\n","Epoch 117/1000\n","4/4 - 2s - 442ms/step - accuracy: 0.9083 - loss: 0.3407 - val_accuracy: 0.8000 - val_loss: 0.7214 - learning_rate: 6.0000e-05\n","Epoch 118/1000\n","4/4 - 2s - 556ms/step - accuracy: 0.8500 - loss: 0.5092 - val_accuracy: 0.8875 - val_loss: 0.4971 - learning_rate: 6.0000e-05\n","Epoch 119/1000\n","4/4 - 3s - 649ms/step - accuracy: 0.8875 - loss: 0.4235 - val_accuracy: 0.8250 - val_loss: 0.5448 - learning_rate: 6.0000e-05\n","Epoch 120/1000\n","4/4 - 2s - 529ms/step - accuracy: 0.8792 - loss: 0.4442 - val_accuracy: 0.8875 - val_loss: 0.3778 - learning_rate: 6.0000e-05\n","Epoch 121/1000\n","4/4 - 2s - 445ms/step - accuracy: 0.9042 - loss: 0.3864 - val_accuracy: 0.7750 - val_loss: 0.6081 - learning_rate: 6.0000e-05\n","Epoch 122/1000\n","4/4 - 2s - 530ms/step - accuracy: 0.8708 - loss: 0.4821 - val_accuracy: 0.8250 - val_loss: 0.6503 - learning_rate: 6.0000e-05\n","Epoch 123/1000\n","4/4 - 2s - 515ms/step - accuracy: 0.8792 - loss: 0.3871 - val_accuracy: 0.8625 - val_loss: 0.5119 - learning_rate: 6.0000e-05\n","Epoch 124/1000\n","4/4 - 2s - 464ms/step - accuracy: 0.9250 - loss: 0.3477 - val_accuracy: 0.8500 - val_loss: 0.6448 - learning_rate: 6.0000e-05\n","Epoch 125/1000\n","4/4 - 2s - 432ms/step - accuracy: 0.9333 - loss: 0.3131 - val_accuracy: 0.8375 - val_loss: 0.4968 - learning_rate: 6.0000e-05\n","Epoch 126/1000\n","4/4 - 2s - 439ms/step - accuracy: 0.8708 - loss: 0.4100 - val_accuracy: 0.9000 - val_loss: 0.3486 - learning_rate: 6.0000e-05\n","Epoch 127/1000\n","4/4 - 2s - 463ms/step - accuracy: 0.9042 - loss: 0.3260 - val_accuracy: 0.8625 - val_loss: 0.5034 - learning_rate: 6.0000e-05\n","Epoch 128/1000\n","4/4 - 2s - 421ms/step - accuracy: 0.8958 - loss: 0.3712 - val_accuracy: 0.8125 - val_loss: 0.6985 - learning_rate: 6.0000e-05\n","Epoch 129/1000\n","4/4 - 2s - 451ms/step - accuracy: 0.8750 - loss: 0.4600 - val_accuracy: 0.8625 - val_loss: 0.4730 - learning_rate: 6.0000e-05\n","Epoch 130/1000\n","4/4 - 2s - 446ms/step - accuracy: 0.8875 - loss: 0.3865 - val_accuracy: 0.8250 - val_loss: 0.5633 - learning_rate: 6.0000e-05\n","Epoch 131/1000\n","4/4 - 2s - 445ms/step - accuracy: 0.9000 - loss: 0.3546 - val_accuracy: 0.8875 - val_loss: 0.5492 - learning_rate: 6.0000e-05\n","Epoch 132/1000\n","4/4 - 2s - 441ms/step - accuracy: 0.9083 - loss: 0.3888 - val_accuracy: 0.8250 - val_loss: 0.5800 - learning_rate: 6.0000e-05\n","Epoch 133/1000\n","4/4 - 2s - 438ms/step - accuracy: 0.9167 - loss: 0.3437 - val_accuracy: 0.8750 - val_loss: 0.4289 - learning_rate: 6.0000e-05\n","Epoch 134/1000\n","4/4 - 2s - 435ms/step - accuracy: 0.9042 - loss: 0.3791 - val_accuracy: 0.8125 - val_loss: 0.6455 - learning_rate: 6.0000e-05\n","Epoch 135/1000\n","4/4 - 2s - 427ms/step - accuracy: 0.8917 - loss: 0.3935 - val_accuracy: 0.8375 - val_loss: 0.5091 - learning_rate: 6.0000e-05\n","Epoch 136/1000\n","4/4 - 2s - 479ms/step - accuracy: 0.9083 - loss: 0.3900 - val_accuracy: 0.8250 - val_loss: 0.6382 - learning_rate: 6.0000e-05\n","Epoch 137/1000\n","4/4 - 2s - 558ms/step - accuracy: 0.8833 - loss: 0.3642 - val_accuracy: 0.8500 - val_loss: 0.5131 - learning_rate: 6.0000e-05\n","Epoch 138/1000\n","4/4 - 2s - 512ms/step - accuracy: 0.9125 - loss: 0.3051 - val_accuracy: 0.8000 - val_loss: 0.7575 - learning_rate: 6.0000e-05\n","Epoch 139/1000\n","4/4 - 2s - 484ms/step - accuracy: 0.8750 - loss: 0.3681 - val_accuracy: 0.8250 - val_loss: 0.5483 - learning_rate: 6.0000e-05\n","Epoch 140/1000\n","4/4 - 2s - 436ms/step - accuracy: 0.8750 - loss: 0.3512 - val_accuracy: 0.8500 - val_loss: 0.5208 - learning_rate: 6.0000e-05\n","Epoch 141/1000\n","4/4 - 2s - 440ms/step - accuracy: 0.9042 - loss: 0.3922 - val_accuracy: 0.8000 - val_loss: 0.7333 - learning_rate: 6.0000e-05\n","Epoch 142/1000\n","4/4 - 2s - 432ms/step - accuracy: 0.8625 - loss: 0.4611 - val_accuracy: 0.8875 - val_loss: 0.5221 - learning_rate: 6.0000e-05\n","Epoch 143/1000\n","4/4 - 2s - 441ms/step - accuracy: 0.9000 - loss: 0.3175 - val_accuracy: 0.8375 - val_loss: 0.7269 - learning_rate: 6.0000e-05\n","Epoch 144/1000\n","4/4 - 2s - 496ms/step - accuracy: 0.9042 - loss: 0.3245 - val_accuracy: 0.9000 - val_loss: 0.3082 - learning_rate: 6.0000e-05\n","Epoch 145/1000\n","4/4 - 2s - 446ms/step - accuracy: 0.8958 - loss: 0.3291 - val_accuracy: 0.8125 - val_loss: 0.5874 - learning_rate: 6.0000e-05\n","Epoch 146/1000\n","4/4 - 2s - 436ms/step - accuracy: 0.9083 - loss: 0.3622 - val_accuracy: 0.9000 - val_loss: 0.4531 - learning_rate: 6.0000e-05\n","Epoch 147/1000\n","4/4 - 2s - 427ms/step - accuracy: 0.9042 - loss: 0.3434 - val_accuracy: 0.8625 - val_loss: 0.5350 - learning_rate: 6.0000e-05\n","Epoch 148/1000\n","4/4 - 2s - 426ms/step - accuracy: 0.9292 - loss: 0.3435 - val_accuracy: 0.8875 - val_loss: 0.5356 - learning_rate: 6.0000e-05\n","Epoch 149/1000\n","4/4 - 2s - 445ms/step - accuracy: 0.8833 - loss: 0.4159 - val_accuracy: 0.8500 - val_loss: 0.4533 - learning_rate: 6.0000e-05\n","Epoch 150/1000\n","4/4 - 2s - 452ms/step - accuracy: 0.9042 - loss: 0.3807 - val_accuracy: 0.8375 - val_loss: 0.6026 - learning_rate: 6.0000e-05\n","Epoch 151/1000\n","4/4 - 2s - 426ms/step - accuracy: 0.9167 - loss: 0.3014 - val_accuracy: 0.8750 - val_loss: 0.4464 - learning_rate: 6.0000e-05\n","Epoch 152/1000\n","4/4 - 2s - 456ms/step - accuracy: 0.8750 - loss: 0.3987 - val_accuracy: 0.9125 - val_loss: 0.3494 - learning_rate: 6.0000e-05\n","Epoch 153/1000\n","4/4 - 2s - 426ms/step - accuracy: 0.9083 - loss: 0.3275 - val_accuracy: 0.8375 - val_loss: 0.4727 - learning_rate: 6.0000e-05\n","Epoch 154/1000\n","4/4 - 2s - 433ms/step - accuracy: 0.8917 - loss: 0.3634 - val_accuracy: 0.8750 - val_loss: 0.4917 - learning_rate: 6.0000e-05\n","Epoch 155/1000\n","4/4 - 2s - 447ms/step - accuracy: 0.8875 - loss: 0.3620 - val_accuracy: 0.7875 - val_loss: 0.6033 - learning_rate: 6.0000e-05\n","Epoch 156/1000\n","4/4 - 2s - 459ms/step - accuracy: 0.8875 - loss: 0.3527 - val_accuracy: 0.8625 - val_loss: 0.4144 - learning_rate: 6.0000e-05\n","Epoch 157/1000\n","4/4 - 2s - 447ms/step - accuracy: 0.9250 - loss: 0.2737 - val_accuracy: 0.8750 - val_loss: 0.5897 - learning_rate: 6.0000e-05\n","Epoch 158/1000\n","4/4 - 2s - 446ms/step - accuracy: 0.9083 - loss: 0.3437 - val_accuracy: 0.7625 - val_loss: 0.6342 - learning_rate: 6.0000e-05\n","Epoch 159/1000\n","4/4 - 2s - 453ms/step - accuracy: 0.9042 - loss: 0.3509 - val_accuracy: 0.8875 - val_loss: 0.4844 - learning_rate: 6.0000e-05\n","Epoch 160/1000\n","4/4 - 2s - 438ms/step - accuracy: 0.9208 - loss: 0.2986 - val_accuracy: 0.8250 - val_loss: 0.5198 - learning_rate: 6.0000e-05\n","Epoch 161/1000\n","4/4 - 2s - 420ms/step - accuracy: 0.9000 - loss: 0.3531 - val_accuracy: 0.8750 - val_loss: 0.5907 - learning_rate: 6.0000e-05\n","Epoch 162/1000\n","4/4 - 2s - 421ms/step - accuracy: 0.9167 - loss: 0.2776 - val_accuracy: 0.7875 - val_loss: 0.7038 - learning_rate: 6.0000e-05\n","Epoch 163/1000\n","4/4 - 2s - 462ms/step - accuracy: 0.9042 - loss: 0.3414 - val_accuracy: 0.8625 - val_loss: 0.4034 - learning_rate: 6.0000e-05\n","Epoch 164/1000\n","\n","Epoch 164: ReduceLROnPlateau reducing learning rate to 1.2000000424450263e-05.\n","4/4 - 2s - 457ms/step - accuracy: 0.8958 - loss: 0.3181 - val_accuracy: 0.8375 - val_loss: 0.4895 - learning_rate: 6.0000e-05\n","Epoch 165/1000\n","4/4 - 2s - 435ms/step - accuracy: 0.9250 - loss: 0.3037 - val_accuracy: 0.8750 - val_loss: 0.5602 - learning_rate: 1.2000e-05\n","Epoch 166/1000\n","4/4 - 2s - 439ms/step - accuracy: 0.9292 - loss: 0.2768 - val_accuracy: 0.8875 - val_loss: 0.4994 - learning_rate: 1.2000e-05\n","Epoch 167/1000\n","4/4 - 2s - 440ms/step - accuracy: 0.9375 - loss: 0.2668 - val_accuracy: 0.8125 - val_loss: 0.5718 - learning_rate: 1.2000e-05\n","Epoch 168/1000\n","4/4 - 2s - 425ms/step - accuracy: 0.8833 - loss: 0.3758 - val_accuracy: 0.8750 - val_loss: 0.4435 - learning_rate: 1.2000e-05\n","Epoch 169/1000\n","4/4 - 2s - 426ms/step - accuracy: 0.9208 - loss: 0.3352 - val_accuracy: 0.8500 - val_loss: 0.5303 - learning_rate: 1.2000e-05\n","Epoch 170/1000\n","4/4 - 2s - 435ms/step - accuracy: 0.9167 - loss: 0.2934 - val_accuracy: 0.8375 - val_loss: 0.5403 - learning_rate: 1.2000e-05\n","Epoch 171/1000\n","4/4 - 2s - 421ms/step - accuracy: 0.8792 - loss: 0.3398 - val_accuracy: 0.8625 - val_loss: 0.4961 - learning_rate: 1.2000e-05\n","Epoch 172/1000\n","4/4 - 2s - 421ms/step - accuracy: 0.9083 - loss: 0.3390 - val_accuracy: 0.9125 - val_loss: 0.3783 - learning_rate: 1.2000e-05\n","Epoch 173/1000\n","4/4 - 2s - 426ms/step - accuracy: 0.9542 - loss: 0.2346 - val_accuracy: 0.8750 - val_loss: 0.4813 - learning_rate: 1.2000e-05\n","Epoch 174/1000\n","4/4 - 2s - 430ms/step - accuracy: 0.9167 - loss: 0.2852 - val_accuracy: 0.8375 - val_loss: 0.5496 - learning_rate: 1.2000e-05\n","Epoch 175/1000\n","4/4 - 2s - 433ms/step - accuracy: 0.9125 - loss: 0.3496 - val_accuracy: 0.8000 - val_loss: 0.4587 - learning_rate: 1.2000e-05\n","Epoch 176/1000\n","4/4 - 2s - 440ms/step - accuracy: 0.9083 - loss: 0.3068 - val_accuracy: 0.8625 - val_loss: 0.5979 - learning_rate: 1.2000e-05\n","Epoch 177/1000\n","4/4 - 2s - 468ms/step - accuracy: 0.9042 - loss: 0.3415 - val_accuracy: 0.8375 - val_loss: 0.5349 - learning_rate: 1.2000e-05\n","Epoch 178/1000\n","4/4 - 2s - 494ms/step - accuracy: 0.9167 - loss: 0.2941 - val_accuracy: 0.8250 - val_loss: 0.6176 - learning_rate: 1.2000e-05\n","Epoch 179/1000\n","4/4 - 2s - 437ms/step - accuracy: 0.9083 - loss: 0.3569 - val_accuracy: 0.9125 - val_loss: 0.4588 - learning_rate: 1.2000e-05\n","Epoch 180/1000\n","4/4 - 2s - 426ms/step - accuracy: 0.9083 - loss: 0.3001 - val_accuracy: 0.8000 - val_loss: 0.5896 - learning_rate: 1.2000e-05\n","Epoch 181/1000\n","4/4 - 2s - 432ms/step - accuracy: 0.8875 - loss: 0.3304 - val_accuracy: 0.8250 - val_loss: 0.5166 - learning_rate: 1.2000e-05\n","Epoch 182/1000\n","4/4 - 2s - 430ms/step - accuracy: 0.9292 - loss: 0.2824 - val_accuracy: 0.8250 - val_loss: 0.6351 - learning_rate: 1.2000e-05\n","Epoch 183/1000\n","4/4 - 2s - 423ms/step - accuracy: 0.9125 - loss: 0.3103 - val_accuracy: 0.8750 - val_loss: 0.5706 - learning_rate: 1.2000e-05\n","Epoch 184/1000\n","\n","Epoch 184: ReduceLROnPlateau reducing learning rate to 2.4000000848900527e-06.\n","4/4 - 2s - 444ms/step - accuracy: 0.8792 - loss: 0.3466 - val_accuracy: 0.8375 - val_loss: 0.4844 - learning_rate: 1.2000e-05\n","Epoch 185/1000\n","4/4 - 2s - 443ms/step - accuracy: 0.9250 - loss: 0.2782 - val_accuracy: 0.9125 - val_loss: 0.3600 - learning_rate: 2.4000e-06\n","Epoch 186/1000\n","4/4 - 2s - 465ms/step - accuracy: 0.9375 - loss: 0.2445 - val_accuracy: 0.7875 - val_loss: 0.7587 - learning_rate: 2.4000e-06\n","Epoch 187/1000\n","4/4 - 2s - 503ms/step - accuracy: 0.9208 - loss: 0.2781 - val_accuracy: 0.8375 - val_loss: 0.4997 - learning_rate: 2.4000e-06\n","Epoch 188/1000\n","4/4 - 2s - 461ms/step - accuracy: 0.9250 - loss: 0.2511 - val_accuracy: 0.8375 - val_loss: 0.5167 - learning_rate: 2.4000e-06\n","Epoch 189/1000\n","4/4 - 2s - 423ms/step - accuracy: 0.9083 - loss: 0.3081 - val_accuracy: 0.8875 - val_loss: 0.3984 - learning_rate: 2.4000e-06\n","Epoch 190/1000\n","4/4 - 2s - 425ms/step - accuracy: 0.9167 - loss: 0.3128 - val_accuracy: 0.9000 - val_loss: 0.3521 - learning_rate: 2.4000e-06\n","Epoch 191/1000\n","4/4 - 2s - 428ms/step - accuracy: 0.9458 - loss: 0.2770 - val_accuracy: 0.8125 - val_loss: 0.5683 - learning_rate: 2.4000e-06\n","Epoch 192/1000\n","4/4 - 2s - 420ms/step - accuracy: 0.8875 - loss: 0.3648 - val_accuracy: 0.8500 - val_loss: 0.6682 - learning_rate: 2.4000e-06\n","Epoch 193/1000\n","4/4 - 2s - 424ms/step - accuracy: 0.9458 - loss: 0.2917 - val_accuracy: 0.8250 - val_loss: 0.6523 - learning_rate: 2.4000e-06\n","Epoch 194/1000\n","4/4 - 2s - 475ms/step - accuracy: 0.9125 - loss: 0.3179 - val_accuracy: 0.8750 - val_loss: 0.5381 - learning_rate: 2.4000e-06\n","Epoch 194: early stopping\n","Restoring model weights from the end of the best epoch: 144.\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step \n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Training accuracy: 0.8833333333333333\n","Validation accuracy: 0.8875\n","Test accuracy: 0.925\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Define the CNN model for classification\n","def build_cnn_model(input_shape: tuple, num_classes: int) -> Model:\n","    inputs = Input(shape=input_shape)\n","    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Conv2D(64, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Conv2D(128, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Flatten()(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dense(num_classes, activation='softmax')(x)  # Output layer with softmax activation\n","    model = Model(inputs=inputs, outputs=x)\n","    return model\n","\n","# Build and compile the CNN model\n","num_classes = 40  # Number of classes in your dataset\n","input_shape = (112, 92, 1)  # Update based on your image size and color mode\n","cnn_model = build_cnn_model(input_shape, num_classes)\n","cnn_model.compile(optimizer=Adam(learning_rate=0.0003), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Define the ImageDataGenerator for data augmentation and loading\n","def build_aug_generator() -> ImageDataGenerator:\n","    return ImageDataGenerator(\n","        rescale=1./255,\n","        zoom_range=0.2,\n","        rotation_range=5,\n","        width_shift_range=0.1,\n","        height_shift_range=0.1,\n","        brightness_range=[0.8, 1.2],\n","        horizontal_flip=True,\n","        fill_mode='nearest'\n","    )\n","\n","def build_dataset(gen: ImageDataGenerator, df: pd.DataFrame, shuffle: bool=False, batch_size: int=64):\n","    return gen.flow_from_dataframe(\n","        df,\n","        x_col='image',\n","        y_col='label',\n","        target_size=(112, 92),\n","        color_mode='grayscale',\n","        class_mode='categorical',\n","        batch_size=batch_size,\n","        shuffle=shuffle\n","    )\n","\n","# Define the callbacks\n","early_stopping = EarlyStopping(\n","    monitor='val_loss', \n","    patience=50, \n","    restore_best_weights=True, \n","    verbose=1\n",")\n","\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_loss', \n","    factor=0.2, \n","    patience=20, \n","    verbose=1, \n","    min_lr=1e-6\n",")\n","\n","# Build dataset generators\n","train_datagen = build_aug_generator()\n","train_ds = build_dataset(train_datagen, df_train, shuffle=True)\n","\n","val_datagen = build_aug_generator()\n","val_ds = build_dataset(val_datagen, df_val)\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","test_ds = build_dataset(test_datagen, df_test, batch_size=1)\n","\n","# Train the CNN model\n","history = cnn_model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=1000,\n","    callbacks=[early_stopping, reduce_lr],\n","    verbose=2\n",")\n","\n","# Extract features from the CNN model\n","def extract_features(model: Model, data_gen: ImageDataGenerator, df: pd.DataFrame) -> np.ndarray:\n","    features = []\n","    labels = []\n","    for batch in data_gen:\n","        imgs, lbls = batch\n","        feature_batch = model.predict(imgs)\n","        features.append(feature_batch)\n","        labels.extend(np.argmax(lbls, axis=1))  # Assuming lbls are one-hot encoded\n","        if len(features) * data_gen.batch_size >= len(df):\n","            break\n","    return np.vstack(features), np.array(labels)\n","\n","# Extract features for training, validation, and testing sets\n","train_features, y_train = extract_features(cnn_model, train_ds, df_train)\n","val_features, y_val = extract_features(cnn_model, val_ds, df_val)\n","test_features, y_test = extract_features(cnn_model, test_ds, df_test)\n","\n","# Define and train the KNN classifier\n","knn_classifier = KNeighborsClassifier(n_neighbors=5)\n","knn_classifier.fit(train_features, y_train)\n","\n","# Predict and evaluate\n","train_predictions = knn_classifier.predict(train_features)\n","val_predictions = knn_classifier.predict(val_features)\n","test_predictions = knn_classifier.predict(test_features)\n","\n","print(f'Training accuracy: {accuracy_score(y_train, train_predictions)}')\n","print(f'Validation accuracy: {accuracy_score(y_val, val_predictions)}')\n","print(f'Test accuracy: {accuracy_score(y_test, test_predictions)}')\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.9250\n","Test Precision: 0.9500\n","Test Recall: 0.9250\n","Test F1 Score: 0.9200\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Predict using the KNN classifier\n","test_predictions = knn_classifier.predict(test_features)\n","\n","# Calculate accuracy, precision, recall, and F1 score\n","accuracy = accuracy_score(y_test, test_predictions)\n","precision = precision_score(y_test, test_predictions, average='weighted')  # Use 'weighted' for multi-class classification\n","recall = recall_score(y_test, test_predictions, average='weighted')      # Use 'weighted' for multi-class classification\n","f1 = f1_score(y_test, test_predictions, average='weighted')               # Use 'weighted' for multi-class classification\n","\n","print(f'Test Accuracy: {accuracy:.4f}')\n","print(f'Test Precision: {precision:.4f}')\n","print(f'Test Recall: {recall:.4f}')\n","print(f'Test F1 Score: {f1:.4f}')\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","def build_cnn_model(input_shape: tuple, num_classes: int) -> Model:\n","    inputs = Input(shape=input_shape)\n","    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Conv2D(64, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Conv2D(128, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Flatten()(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dense(num_classes, activation='softmax')(x)  # Output layer with softmax activation\n","    model = Model(inputs=inputs, outputs=x)\n","    return model\n","\n","# Build and compile the CNN model\n","num_classes = 40  # Number of classes in your dataset\n","input_shape = (112, 92, 1)  # Update based on your image size and color mode\n","cnn_model = build_cnn_model(input_shape, num_classes)\n","cnn_model.compile(optimizer=Adam(learning_rate=0.0003), loss='categorical_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13824</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,769,600</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,160</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m92\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m53\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13824\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,769,600\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m5,160\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,867,432</span> (7.12 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,867,432\u001b[0m (7.12 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,867,432</span> (7.12 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,867,432\u001b[0m (7.12 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["cnn_model.summary()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":244146,"sourceId":847361,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
